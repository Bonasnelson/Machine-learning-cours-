{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['pregnants', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "dframe = pd.read_csv('../dataset/Pima.csv', header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/Maternal Health Risk Data Set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CodeLevel'] = le.fit_transform(data.RiskLevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['CodeLevel', 'RiskLevel'], axis=1 )\n",
    "y = data.CodeLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dframe.drop(['label'], axis = 1)\n",
    "y = dframe.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = DecisionTreeClassifier()\n",
    "Model_tree = Model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75, 24],\n",
       "       [25, 30]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test , Model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {'criterion': ['gini', 'entropy'], 'max_depth': np.arange(4, 40)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Grid = GridSearchCV(Model, params_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "       21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,\n",
       "       38, 39])})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7345061975209916"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87, 12],\n",
       "       [20, 35]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test , Model_Grid.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_param_for_Decision_Tree(number_cv=2):\n",
    "    params_grid = {'criterion': ['gini', 'entropy'], 'max_depth': np.arange(4, 40)}\n",
    "    # grid sarch\n",
    "    list_best_param = []\n",
    "    list_best_scores = []\n",
    "    for i in range(2, number_cv+1):   \n",
    "        df_grid = GridSearchCV(estimator=Model, param_grid= params_grid, cv= i)\n",
    "        df_grid.fit(X_train, y_train)\n",
    "        list_best_param.append(df_grid.best_params_)\n",
    "        list_best_scores.append(df_grid.best_score_)\n",
    "# crate a data frame with the cv and the bst score\n",
    "    print(pd.DataFrame(list_best_scores, index = range(2, number_cv+1), \n",
    "            columns = ['Best score']).sort_index())\n",
    "    best_score_index = 0\n",
    "# looks for the params with the best score\n",
    "    for i in list_best_scores:\n",
    "        if i > i+1:\n",
    "            best_score_index = i.index\n",
    "# best score\n",
    "    # best = list_best_scores.sort()\n",
    "    # print(best)\n",
    "    # print(list_best_scores)\n",
    "    print('best score: ',list_best_scores[number_cv-2])\n",
    "# give the bst params\n",
    "    print(list_best_param[best_score_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Best score\n",
      "2     0.697068\n",
      "3     0.713335\n",
      "4     0.729607\n",
      "5     0.734506\n",
      "6     0.739419\n",
      "7     0.718316\n",
      "8     0.740986\n",
      "9     0.745998\n",
      "10    0.740984\n",
      "11    0.734652\n",
      "12    0.742647\n",
      "13    0.734622\n",
      "14    0.739429\n",
      "15    0.737724\n",
      "16    0.747427\n",
      "17    0.737591\n",
      "18    0.740850\n",
      "19    0.739434\n",
      "20    0.736183\n",
      "best score:  0.7361827956989248\n",
      "{'criterion': 'entropy', 'max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "best_param_for_Decision_Tree(number_cv=20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa7146d4c1a12161272e7931a5de19d4c46ea1ea93acbb11666f6ac8b35f8224"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
